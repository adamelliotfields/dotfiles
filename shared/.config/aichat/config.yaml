# https://github.com/sigoden/aichat/blob/main/config.example.yaml
save: false
model: pplx:mixtral-8x22b-instruct
compress_threshold: 0

clients:
- type: claude
- type: gemini
- type: openai
- type: localai
  name: pplx
  api_base: https://api.perplexity.ai
  models:
  - name: sonar-small-online
    max_input_tokens: 12000
  - name: sonar-medium-online
    max_input_tokens: 12000
  - name: mistral-7b-instruct
    max_input_tokens: 16384
  - name: mixtral-8x7b-instruct
    max_input_tokens: 16384
  - name: mixtral-8x22b-instruct
    max_input_tokens: 16384
  - name: codellama-70b-instruct
    max_input_tokens: 16384
